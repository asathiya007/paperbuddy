{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnyY9S9mUsyp"
      },
      "source": [
        "# PaperBuddy\n",
        "\n",
        "PaperBuddy is an AI assistant that answers questions about papers on ArXiv (arxiv.org) using an LLM (Llama-3.3-70b-instruct) and retrieval augmented generation (RAG)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAooY3ldWfYP"
      },
      "source": [
        "## Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SPIyRVboKU8j",
        "outputId": "c7a52bb9-488e-4f31-e779-cc5bb3e0e674"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting arxiv==2.2.0 (from -r requirements.txt (line 1))\n",
            "  Downloading arxiv-2.2.0-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting faiss-cpu==1.11.0 (from -r requirements.txt (line 2))\n",
            "  Downloading faiss_cpu-1.11.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: langchain==0.3.26 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (0.3.26)\n",
            "Collecting langchain-community==0.3.26 (from -r requirements.txt (line 4))\n",
            "  Downloading langchain_community-0.3.26-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting langchain-nvidia-ai-endpoints==0.3.10 (from -r requirements.txt (line 5))\n",
            "  Downloading langchain_nvidia_ai_endpoints-0.3.10-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting pymupdf==1.26.1 (from -r requirements.txt (line 6))\n",
            "  Downloading pymupdf-1.26.1-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (3.4 kB)\n",
            "Collecting python-dotenv==1.1.1 (from -r requirements.txt (line 7))\n",
            "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting feedparser~=6.0.10 (from arxiv==2.2.0->-r requirements.txt (line 1))\n",
            "  Downloading feedparser-6.0.11-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: requests~=2.32.0 in /usr/local/lib/python3.11/dist-packages (from arxiv==2.2.0->-r requirements.txt (line 1)) (2.32.3)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu==1.11.0->-r requirements.txt (line 2)) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu==1.11.0->-r requirements.txt (line 2)) (24.2)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.66 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.26->-r requirements.txt (line 3)) (0.3.67)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.26->-r requirements.txt (line 3)) (0.3.8)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.26->-r requirements.txt (line 3)) (0.4.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.26->-r requirements.txt (line 3)) (2.11.7)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.26->-r requirements.txt (line 3)) (2.0.41)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.26->-r requirements.txt (line 3)) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.3.26->-r requirements.txt (line 4)) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.3.26->-r requirements.txt (line 4)) (8.5.0)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community==0.3.26->-r requirements.txt (line 4))\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community==0.3.26->-r requirements.txt (line 4))\n",
            "  Downloading pydantic_settings-2.10.1-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community==0.3.26->-r requirements.txt (line 4))\n",
            "  Downloading httpx_sse-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
            "Collecting filetype<2.0.0,>=1.2.0 (from langchain-nvidia-ai-endpoints==0.3.10->-r requirements.txt (line 5))\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.26->-r requirements.txt (line 4)) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.26->-r requirements.txt (line 4)) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.26->-r requirements.txt (line 4)) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.26->-r requirements.txt (line 4)) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.26->-r requirements.txt (line 4)) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.26->-r requirements.txt (line 4)) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.26->-r requirements.txt (line 4)) (1.20.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.26->-r requirements.txt (line 4))\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.26->-r requirements.txt (line 4))\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting sgmllib3k (from feedparser~=6.0.10->arxiv==2.2.0->-r requirements.txt (line 1))\n",
            "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain==0.3.26->-r requirements.txt (line 3)) (1.33)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain==0.3.26->-r requirements.txt (line 3)) (4.14.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain==0.3.26->-r requirements.txt (line 3)) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain==0.3.26->-r requirements.txt (line 3)) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain==0.3.26->-r requirements.txt (line 3)) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain==0.3.26->-r requirements.txt (line 3)) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.26->-r requirements.txt (line 3)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.26->-r requirements.txt (line 3)) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.26->-r requirements.txt (line 3)) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests~=2.32.0->arxiv==2.2.0->-r requirements.txt (line 1)) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests~=2.32.0->arxiv==2.2.0->-r requirements.txt (line 1)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests~=2.32.0->arxiv==2.2.0->-r requirements.txt (line 1)) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests~=2.32.0->arxiv==2.2.0->-r requirements.txt (line 1)) (2025.6.15)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.3.26->-r requirements.txt (line 3)) (3.2.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain==0.3.26->-r requirements.txt (line 3)) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain==0.3.26->-r requirements.txt (line 3)) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain==0.3.26->-r requirements.txt (line 3)) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain==0.3.26->-r requirements.txt (line 3)) (3.0.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.26->-r requirements.txt (line 4))\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain==0.3.26->-r requirements.txt (line 3)) (1.3.1)\n",
            "Downloading arxiv-2.2.0-py3-none-any.whl (11 kB)\n",
            "Downloading faiss_cpu-1.11.0-cp311-cp311-manylinux_2_28_x86_64.whl (31.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m54.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_community-0.3.26-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m78.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_nvidia_ai_endpoints-0.3.10-py3-none-any.whl (41 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.6/41.6 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pymupdf-1.26.1-cp39-abi3-manylinux_2_28_x86_64.whl (24.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m78.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
            "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading feedparser-6.0.11-py3-none-any.whl (81 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.3/81.3 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading httpx_sse-0.4.1-py3-none-any.whl (8.1 kB)\n",
            "Downloading pydantic_settings-2.10.1-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Building wheels for collected packages: sgmllib3k\n",
            "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6046 sha256=ef8a9c9ad4aaa862c60cec42bd6c27dea1e7a9a24732e8ff0c8c3ec2094aa1f4\n",
            "  Stored in directory: /root/.cache/pip/wheels/3b/25/2a/105d6a15df6914f4d15047691c6c28f9052cc1173e40285d03\n",
            "Successfully built sgmllib3k\n",
            "Installing collected packages: sgmllib3k, filetype, python-dotenv, pymupdf, mypy-extensions, marshmallow, httpx-sse, feedparser, faiss-cpu, typing-inspect, arxiv, pydantic-settings, dataclasses-json, langchain-nvidia-ai-endpoints, langchain-community\n",
            "Successfully installed arxiv-2.2.0 dataclasses-json-0.6.7 faiss-cpu-1.11.0 feedparser-6.0.11 filetype-1.2.0 httpx-sse-0.4.1 langchain-community-0.3.26 langchain-nvidia-ai-endpoints-0.3.10 marshmallow-3.26.1 mypy-extensions-1.1.0 pydantic-settings-2.10.1 pymupdf-1.26.1 python-dotenv-1.1.1 sgmllib3k-1.0.0 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1xFoDelWk-F"
      },
      "source": [
        "## Discuss papers with PaperBuddy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "w2B3JJypS7ZP"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "from paperbuddy import PaperBuddy\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhxt5UF0TAz1",
        "outputId": "ae162719-1c3a-4f18-b1d8-f08d95de5f4d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:PaperBuddy_Logger:Loaded environment variables from .env file.\n",
            "INFO:PaperBuddy_Logger:Using nvidia/nv-embed-v1 embedding model.\n",
            "INFO:PaperBuddy_Logger:Using meta/llama-3.3-70b-instruct chat model.\n",
            "INFO:PaperBuddy_Logger:Created FAISS conversation store.\n",
            "INFO:PaperBuddy_Logger:Created FAISS document store.\n",
            "INFO:PaperBuddy_Logger:Adding arXiv papers with IDs ['2412.18109'] to document store\n",
            "INFO:PaperBuddy_Logger:Split papers into chunks.\n",
            "INFO:PaperBuddy_Logger:Created paper metadata chunks.\n",
            "INFO:PaperBuddy_Logger:Added paper and metadata chunks to document store.\n"
          ]
        }
      ],
      "source": [
        "ARXIV_PAPER_IDS = [\n",
        "    # The EnvDesign Model: A Method to Solve the Environment Design Problem\n",
        "    '2412.18109'\n",
        "]\n",
        "\n",
        "pb = PaperBuddy(ARXIV_PAPER_IDS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ISwGpD2raHEi"
      },
      "outputs": [],
      "source": [
        "def print_interaction(question):\n",
        "    print(f'Question: {question}\\n\\n')\n",
        "    answer = pb.prompt(question)\n",
        "    print(f'\\n\\nAnswer: {answer}\\n\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TzH-XPuoTzqz",
        "outputId": "0d439dc4-487c-45ff-b01c-eceb5b3746ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What is the EnvDesign model?\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:PaperBuddy_Logger:Retrieved relevant conversation history.\n",
            "INFO:PaperBuddy_Logger:Retrieved relevant context from papers.\n",
            "INFO:PaperBuddy_Logger:Generated chat model response to user input with retrieved conversation history and context.\n",
            "INFO:PaperBuddy_Logger:Split user input and PaperBuddy output into chunks.\n",
            "INFO:PaperBuddy_Logger:Added chunks to conversation store.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Answer: The EnvDesign model is a method that uses graph theory and optimization algorithms to solve the environment design problem, which involves designing pre-production testing environments that take into account the diversity of server/node properties and dynamically emphasize or de-emphasize certain node properties based on current testing priorities.\n",
            "\n",
            "Sources:\n",
            "* The EnvDesign Model: A Method to Solve the Environment Design Problem\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print_interaction('What is the EnvDesign model?')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6IrRg1IgglzL",
        "outputId": "33593eb3-1af3-4121-e0a1-cb40e8db3ddc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What optimization algorithms are used?\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:PaperBuddy_Logger:Retrieved relevant conversation history.\n",
            "INFO:PaperBuddy_Logger:Retrieved relevant context from papers.\n",
            "INFO:PaperBuddy_Logger:Generated chat model response to user input with retrieved conversation history and context.\n",
            "INFO:PaperBuddy_Logger:Split user input and PaperBuddy output into chunks.\n",
            "INFO:PaperBuddy_Logger:Added chunks to conversation store.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Answer: The optimization algorithms used include simulated annealing and branch and bound. Specifically, there are 6 simulated annealing algorithms and 12 branch and bound algorithms tested on different instances of the environment design problem.\n",
            "\n",
            "Sources:\n",
            "* The EnvDesign Model: A Method to Solve the Environment Design Problem\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print_interaction('What optimization algorithms are used?')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8BQ9vQMKAe6L",
        "outputId": "f02c7ebb-8dc5-42ca-a282-4a4df1297156"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What do the simulated annealing algorithms do?\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:PaperBuddy_Logger:Retrieved relevant conversation history.\n",
            "INFO:PaperBuddy_Logger:Retrieved relevant context from papers.\n",
            "INFO:PaperBuddy_Logger:Generated chat model response to user input with retrieved conversation history and context.\n",
            "INFO:PaperBuddy_Logger:Split user input and PaperBuddy output into chunks.\n",
            "INFO:PaperBuddy_Logger:Added chunks to conversation store.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Answer: The simulated annealing algorithms iteratively modify individual cliques in a given schedule to produce a new, more optimal schedule. They optimize the expanded coverage schedule with or without preservation of clique cover, and replace each chosen clique with a clique built from a random vertex, all but one of the vertices, or a single vertex in the chosen clique.\n",
            "\n",
            "Sources:\n",
            "* The EnvDesign Model: A Method to Solve the Environment Design Problem\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print_interaction('What do the simulated annealing algorithms do?')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_interaction('What do the branch and bound algorithms do?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_ekf0THvvAr",
        "outputId": "4a997cc6-e9da-4a6b-f700-fb50bca63392"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What do the branch and bound algorithms do?\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:PaperBuddy_Logger:Retrieved relevant conversation history.\n",
            "INFO:PaperBuddy_Logger:Retrieved relevant context from papers.\n",
            "INFO:PaperBuddy_Logger:Generated chat model response to user input with retrieved conversation history and context.\n",
            "INFO:PaperBuddy_Logger:Split user input and PaperBuddy output into chunks.\n",
            "INFO:PaperBuddy_Logger:Added chunks to conversation store.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Answer: The branch and bound algorithms build a schedule, clique by clique, starting from an empty collection of cliques, or modify existing cliques to produce a new, more optimal schedule. They iteratively add cliques to a given schedule until it reaches the desired size, and use strategies such as depth-first or best-first selection to choose the next clique to add.\n",
            "\n",
            "Sources:\n",
            "* The EnvDesign Model: A Method to Solve the Environment Design Problem\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_interaction(\n",
        "    'Which optimization algorithm performs the best in the experiments?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bGleMytQv-VC",
        "outputId": "242dd69f-e652-4a97-c096-b72b51af17ef"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: Which optimization algorithm performs the best in the experiments?\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:PaperBuddy_Logger:Retrieved relevant conversation history.\n",
            "INFO:PaperBuddy_Logger:Retrieved relevant context from papers.\n",
            "INFO:PaperBuddy_Logger:Generated chat model response to user input with retrieved conversation history and context.\n",
            "INFO:PaperBuddy_Logger:Split user input and PaperBuddy output into chunks.\n",
            "INFO:PaperBuddy_Logger:Added chunks to conversation store.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Answer: The optimization algorithms that perform the best in the experiments are algorithms 3.3 and 3.4 (traditional and look-ahead branch and bound to optimize the expanded coverage schedule, with a depth-first-best-first selection strategy) under the dimension-based and combination-based objective functions, and algorithm 1.3 (simulated annealing to optimize the expanded coverage schedule, without preservation of clique cover and replacing each chosen clique with a clique built from all but one of the vertices in the chosen clique) under the relationship-based objective function. In Experiment 2, the best algorithm is 1.2 (simulated annealing to optimize the expanded coverage schedule, with preservation of clique cover and replacing each chosen clique with a clique built from a random vertex).\n",
            "\n",
            "Sources:\n",
            "* The EnvDesign Model: A Method to Solve the Environment Design Problem\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_interaction(\n",
        "    'What do cliques represent in the context of the environment design '\n",
        "    + 'problem?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42MxuzCEwJLu",
        "outputId": "726df87a-4cfd-41a6-ef11-901ef0dca944"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What do cliques represent in the context of the environment design problem?\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:PaperBuddy_Logger:Retrieved relevant conversation history.\n",
            "INFO:PaperBuddy_Logger:Retrieved relevant context from papers.\n",
            "INFO:PaperBuddy_Logger:Generated chat model response to user input with retrieved conversation history and context.\n",
            "INFO:PaperBuddy_Logger:Split user input and PaperBuddy output into chunks.\n",
            "INFO:PaperBuddy_Logger:Added chunks to conversation store.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Answer: In the context of the environment design problem, cliques represent node configurations, where each clique is of size d and contains one vertex from each of the d dimensions. Each node configuration corresponds to a clique of size d in the graph, and the problem of finding the minimal set of node configurations needed to cover each dimension is a more constrained version of the minimum clique cover problem.\n",
            "\n",
            "Sources:\n",
            "* The EnvDesign Model: A Method to Solve the Environment Design Problem\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_interaction('What are some examples of dimensions?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KouUwMRUe2ly",
        "outputId": "86496b03-73bd-4119-fb50-8a9f9650072b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What are some examples of dimensions?\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:PaperBuddy_Logger:Retrieved relevant conversation history.\n",
            "INFO:PaperBuddy_Logger:Retrieved relevant context from papers.\n",
            "INFO:PaperBuddy_Logger:Generated chat model response to user input with retrieved conversation history and context.\n",
            "INFO:PaperBuddy_Logger:Split user input and PaperBuddy output into chunks.\n",
            "INFO:PaperBuddy_Logger:Added chunks to conversation store.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Answer: Examples of dimensions include HW model, BIOS version, and VM type. \n",
            "\n",
            "Sources:\n",
            "* The EnvDesign Model: A Method to Solve the Environment Design Problem\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_interaction('What are schedules?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rak7OLsMdtVI",
        "outputId": "f0703bfd-11fc-4a9e-fe13-7960abe73157"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What are schedules?\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:PaperBuddy_Logger:Retrieved relevant conversation history.\n",
            "INFO:PaperBuddy_Logger:Retrieved relevant context from papers.\n",
            "INFO:PaperBuddy_Logger:Generated chat model response to user input with retrieved conversation history and context.\n",
            "INFO:PaperBuddy_Logger:Split user input and PaperBuddy output into chunks.\n",
            "INFO:PaperBuddy_Logger:Added chunks to conversation store.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Answer: A schedule is a collection of testing configurations, where each configuration has a set of dimension values, one from each dimension. It is generated using algorithms such as branch and bound or simulated annealing to optimize the coverage of dimension values. The schedule is used to test different combinations of dimension values.\n",
            "\n",
            "Sources:\n",
            "* The EnvDesign Model: A Method to Solve the Environment Design Problem\n",
            "* Conversation history\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_interaction('Are cliques the same thing as testing configurations? '\n",
        "                  + 'If so, is it fair to say that schedules are collections '\n",
        "                  + 'of cliques?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5r6TQrsg6ar",
        "outputId": "99e539dd-4173-42b6-af8d-929eef0edc91"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: Are cliques the same thing as testing configurations? If so, is it fair to say that schedules are collections of cliques?\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:PaperBuddy_Logger:Retrieved relevant conversation history.\n",
            "INFO:PaperBuddy_Logger:Retrieved relevant context from papers.\n",
            "INFO:PaperBuddy_Logger:Generated chat model response to user input with retrieved conversation history and context.\n",
            "INFO:PaperBuddy_Logger:Split user input and PaperBuddy output into chunks.\n",
            "INFO:PaperBuddy_Logger:Added chunks to conversation store.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Answer: Yes, cliques and testing configurations are equivalent, as each clique represents a node configuration with one vertex from each dimension. A schedule is a collection of testing configurations, and since testing configurations are equivalent to cliques, it is fair to say that schedules are collections of cliques.\n",
            "Sources:\n",
            "* The EnvDesign Model: A Method to Solve the Environment Design Problem\n",
            "* Conversation history\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QM0Vfez4oMiu",
        "outputId": "8e2f9a76-fdf8-412d-b772-ce7c6aaeb2a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:PaperBuddy_Logger:Saved arXiv paper IDs.\n",
            "INFO:PaperBuddy_Logger:Saved FAISS index for PaperBuddy conversation store.\n",
            "INFO:PaperBuddy_Logger:Saved FAISS index for PaperBuddy document store.\n"
          ]
        }
      ],
      "source": [
        "pb.save_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7Zc0TFit7TP",
        "outputId": "762d95dc-f427-4793-90b2-6cc8dd04d9a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:PaperBuddy_Logger:Loaded environment variables from .env file.\n",
            "INFO:PaperBuddy_Logger:Using nvidia/nv-embed-v1 embedding model.\n",
            "INFO:PaperBuddy_Logger:Using meta/llama-3.3-70b-instruct chat model.\n",
            "INFO:PaperBuddy_Logger:Loaded PaperBuddy conversation store from saved FAISS index.\n",
            "INFO:PaperBuddy_Logger:Loaded PaperBuddy document store from saved FAISS index.\n",
            "INFO:PaperBuddy_Logger:Adding arXiv papers with IDs ['2503.00033'] to document store\n",
            "INFO:PaperBuddy_Logger:Split papers into chunks.\n",
            "INFO:PaperBuddy_Logger:Created paper metadata chunks.\n",
            "INFO:PaperBuddy_Logger:Added paper and metadata chunks to document store.\n"
          ]
        }
      ],
      "source": [
        "NEW_ARXIV_PAPER_IDS = [\n",
        "    # optimizn: a Python Library for Developing Customized Optimization\n",
        "    # Algorithms\n",
        "    '2503.00033'\n",
        "]\n",
        "\n",
        "pb = PaperBuddy(NEW_ARXIV_PAPER_IDS, load_stores=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dDzQMzNpOgWp",
        "outputId": "9d5239a7-96a3-4092-c1c5-4403819a4ffd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What is the optimizn library?\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:PaperBuddy_Logger:Retrieved relevant conversation history.\n",
            "INFO:PaperBuddy_Logger:Retrieved relevant context from papers.\n",
            "INFO:PaperBuddy_Logger:Generated chat model response to user input with retrieved conversation history and context.\n",
            "INFO:PaperBuddy_Logger:Split user input and PaperBuddy output into chunks.\n",
            "INFO:PaperBuddy_Logger:Added chunks to conversation store.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Answer: The optimizn library is a Python library for developing customized optimization algorithms under general optimization algorithm paradigms, including simulated annealing and branch and bound, with continuous training offerings. \n",
            "\n",
            "Sources:\n",
            "* optimizn: a Python Library for Developing Customized Optimization Algorithms\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print_interaction('What is the optimizn library?')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "giuXROuFTp1b",
        "outputId": "8822b2ec-42de-4a37-d55b-53e0cad80279"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What is simulated annealing?\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:PaperBuddy_Logger:Retrieved relevant conversation history.\n",
            "INFO:PaperBuddy_Logger:Retrieved relevant context from papers.\n",
            "INFO:PaperBuddy_Logger:Generated chat model response to user input with retrieved conversation history and context.\n",
            "INFO:PaperBuddy_Logger:Split user input and PaperBuddy output into chunks.\n",
            "INFO:PaperBuddy_Logger:Added chunks to conversation store.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Answer: Simulated annealing is an optimization algorithm inspired by the annealing of solids, where a solution is iteratively modified into a more optimal solution. It features random restarts and occasionally allows modifications that produce a less optimal solution to escape local minima of the cost/objective function.\n",
            "\n",
            "Sources:\n",
            "* optimizn: a Python Library for Developing Customized Optimization Algorithms\n",
            "* The EnvDesign Model: A Method to Solve the Environment Design Problem\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print_interaction('What is simulated annealing?')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CSqRF-7GT8YV",
        "outputId": "4f530808-3d31-4657-b951-c39a80aa9d89"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What is branch and bound?\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:PaperBuddy_Logger:Retrieved relevant conversation history.\n",
            "INFO:PaperBuddy_Logger:Retrieved relevant context from papers.\n",
            "INFO:PaperBuddy_Logger:Generated chat model response to user input with retrieved conversation history and context.\n",
            "INFO:PaperBuddy_Logger:Split user input and PaperBuddy output into chunks.\n",
            "INFO:PaperBuddy_Logger:Added chunks to conversation store.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Answer: Branch and bound is an optimization algorithm that represents the problem space as a tree, where the root node is the original constrained optimization problem and its descendant nodes are more constrained versions of the problem. The algorithm iteratively adds nodes to the tree, pruning nodes that will not lead to a solution more optimal than the most optimal solution seen so far, until it finds the optimal solution.\n",
            "\n",
            "Sources:\n",
            "* optimizn: a Python Library for Developing Customized Optimization Algorithms\n",
            "* The EnvDesign Model: A Method to Solve the Environment Design Problem\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print_interaction('What is branch and bound?')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_interaction('What is continuous training?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MXkJpCYA2p3M",
        "outputId": "0bee153f-856a-4313-f698-17b7cc201e2a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What is continuous training?\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:PaperBuddy_Logger:Retrieved relevant conversation history.\n",
            "INFO:PaperBuddy_Logger:Retrieved relevant context from papers.\n",
            "INFO:PaperBuddy_Logger:Generated chat model response to user input with retrieved conversation history and context.\n",
            "INFO:PaperBuddy_Logger:Split user input and PaperBuddy output into chunks.\n",
            "INFO:PaperBuddy_Logger:Added chunks to conversation store.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Answer: Continuous training refers to the ability to run an optimization algorithm, save its problem parameters, best solution found, and state, and then resume running from that state later. This allows the algorithm to pick up where it left off and potentially produce solutions that get closer to optimality.\n",
            "\n",
            "Sources:\n",
            "* optimizn: a Python Library for Developing Customized Optimization Algorithms\n",
            "* The EnvDesign Model: A Method to Solve the Environment Design Problem\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ha2GkdG7EYT1",
        "outputId": "eda3dce1-6ce3-436c-8cde-fb12a139cce8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: To develop a customized simulated annealing algorithm, what functions does the user have to implement?\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:PaperBuddy_Logger:Retrieved relevant conversation history.\n",
            "INFO:PaperBuddy_Logger:Retrieved relevant context from papers.\n",
            "INFO:PaperBuddy_Logger:Generated chat model response to user input with retrieved conversation history and context.\n",
            "INFO:PaperBuddy_Logger:Split user input and PaperBuddy output into chunks.\n",
            "INFO:PaperBuddy_Logger:Added chunks to conversation store.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Answer: To develop a customized simulated annealing algorithm, the user has to implement the following functions: \n",
            "- get initial solution: Returns the initial solution \n",
            "- next candidate: Produces a new solution by modifying the current solution\n",
            "- cost: Computes the value of the objective function (cost) for a given solution\n",
            "- reset candidate: Produces a new solution that becomes the current solution under the specified reset probability\n",
            "- get temperature: Gets the temperature given the number of iterations since the last random restart.\n",
            "\n",
            "Sources:\n",
            "* optimizn: a Python Library for Developing Customized Optimization Algorithms\n",
            "* The EnvDesign Model: A Method to Solve the Environment Design Problem\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print_interaction(\n",
        "    'To develop a customized simulated annealing algorithm, what '\n",
        "    + 'functions does the user have to implement?')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_interaction(\n",
        "    'Does optimizn\\'s branch and bound implementation allow users to customize '\n",
        "    + 'the order in which the nodes in the tree are selected and evaluated? If '\n",
        "    + 'so, how?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hA-pnJ7crWHN",
        "outputId": "d1d54282-8aa4-4da9-a192-3fd637e54ef5"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: Does optimizn's branch and bound implementation allow users to customize the order in which the nodes in the tree are selected and evaluated? If so, how?\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:PaperBuddy_Logger:Retrieved relevant conversation history.\n",
            "INFO:PaperBuddy_Logger:Retrieved relevant context from papers.\n",
            "INFO:PaperBuddy_Logger:Generated chat model response to user input with retrieved conversation history and context.\n",
            "INFO:PaperBuddy_Logger:Split user input and PaperBuddy output into chunks.\n",
            "INFO:PaperBuddy_Logger:Added chunks to conversation store.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Answer: Yes, optimizn's branch and bound implementation allows users to customize the order in which the nodes in the tree are selected and evaluated. The user can specify the strategy for selecting the next node in the tree to evaluate through the \"bnb selection strategy\" argument in the BnBProblem class constructor. The supported selection strategies are depth-first, depth-first-best-first, and best-first-depth-first.\n",
            "\n",
            "Sources:\n",
            "* optimizn: a Python Library for Developing Customized Optimization Algorithms\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "raQqzr3e0Aqd",
        "outputId": "957a2849-10fd-4088-8e35-f0f3a2dd20bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:PaperBuddy_Logger:Saved arXiv paper IDs.\n",
            "INFO:PaperBuddy_Logger:Saved FAISS index for PaperBuddy conversation store.\n",
            "INFO:PaperBuddy_Logger:Saved FAISS index for PaperBuddy document store.\n"
          ]
        }
      ],
      "source": [
        "pb.save_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "dFoURIui6yQW",
        "outputId": "7e279310-8644-4508-b6a3-5381efb0cb41"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_ed799255-b33a-4460-b4be-4ac278df0c20\", \"paperbuddy_data.zip\", 1672587)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "shutil.make_archive('paperbuddy_data', 'zip', './paperbuddy_data')\n",
        "files.download('./paperbuddy_data.zip')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}